{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d98d5a",
   "metadata": {},
   "source": [
    "# Projeto: Mini Mercado Inteligente\n",
    "\n",
    "**Objetivo:** construir um notebook completo integrando ETL, análise descritiva, mineração de regras (Apriori), similaridade (Jaccard) e visualizações para uma rede de supermercados do Vale do Ribeira.\n",
    "\n",
    "**Entrega:** `Projeto_MiniMercado.ipynb` — contém explicações, código e gráficos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba7862",
   "metadata": {},
   "source": [
    "## 1) Importações e geração do dataset simulado\n",
    "\n",
    "Nesta seção criamos um dataset de vendas simulado com clientes, produtos e transações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parâmetros do dataset\n",
    "n_customers = 200    # número de clientes únicos\n",
    "n_products = 50      # número de produtos diferentes\n",
    "n_transactions = 2000  # número de transações\n",
    "\n",
    "# Gerar produtos\n",
    "products = [f\"Produto_{i:02d}\" for i in range(1, n_products+1)]\n",
    "prices = np.round(np.random.uniform(2.0, 120.0, size=n_products), 2)\n",
    "product_df = pd.DataFrame({'product_id': products, 'price': prices})\n",
    "\n",
    "# Gerar clientes\n",
    "customers = [f\"Cliente_{i:03d}\" for i in range(1, n_customers+1)]\n",
    "\n",
    "# Gerar transações: cada transação tem um cliente, data, e uma lista de produtos comprados\n",
    "transactions = []\n",
    "for t in range(n_transactions):\n",
    "    customer = random.choice(customers)\n",
    "    # número de itens por transação (mais prob. compras pequenas)\n",
    "    size = np.random.choice([1,2,3,4,5,6], p=[0.25,0.25,0.2,0.15,0.1,0.05])\n",
    "    items = list(np.random.choice(products, size=size, replace=False))\n",
    "    # assign quantities and compute transaction total\n",
    "    quantities = list(np.random.randint(1,4,size=len(items)))\n",
    "    date = datetime.date(2025, random.randint(1,12), random.randint(1,28))\n",
    "    transactions.append({'transaction_id': f\"T{t+1:05d}\", 'customer_id': customer, 'date': pd.to_datetime(date), 'items': items, 'quantities': quantities})\n",
    "\n",
    "# transformar em DataFrame 'explodido' (cada linha = um item da transação)\n",
    "rows = []\n",
    "for tr in transactions:\n",
    "    for prod, qty in zip(tr['items'], tr['quantities']):\n",
    "        price = float(product_df.loc[product_df['product_id']==prod,'price'].values[0])\n",
    "        rows.append({'transaction_id': tr['transaction_id'], 'customer_id': tr['customer_id'], 'date': tr['date'], 'product_id': prod, 'quantity': qty, 'price': price, 'total': qty*price})\n",
    "\n",
    "sales = pd.DataFrame(rows)\n",
    "sales.reset_index(drop=True, inplace=True)\n",
    "print('Dataset criado: linhas =', len(sales))\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85617380",
   "metadata": {},
   "source": [
    "## 2) ETL: carregar e tratar a base\n",
    "\n",
    "Etapas realizadas:\n",
    "- verificação de tipos\n",
    "- remoção de possíveis duplicatas\n",
    "- agregação por transação quando necessário\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88edbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ETL simples e verificações\n",
    "df = sales.copy()\n",
    "# tipos\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# remover duplicatas estranhas\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# criar coluna 'transaction_total' agregada por transaction_id\n",
    "transaction_totals = df.groupby('transaction_id')['total'].sum().reset_index().rename(columns={'total':'transaction_total'})\n",
    "df = df.merge(transaction_totals, on='transaction_id', how='left')\n",
    "\n",
    "# quick checks\n",
    "print('Transações únicas:', df['transaction_id'].nunique())\n",
    "print('Clientes únicos:', df['customer_id'].nunique())\n",
    "print('Produtos únicos nas vendas:', df['product_id'].nunique())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee7079",
   "metadata": {},
   "source": [
    "## 3) Análise Descritiva\n",
    "\n",
    "Gerar estatísticas sobre produtos, valores e quantidades. Mostraremos: top produtos por quantidade e por receita, e estatísticas resumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ee66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top 5 produtos por quantidade vendida\n",
    "top_q = df.groupby('product_id')['quantity'].sum().sort_values(ascending=False).head(10)\n",
    "top_q5 = top_q.head(5)\n",
    "\n",
    "# Top 5 produtos por receita\n",
    "top_rev = df.groupby('product_id')['total'].sum().sort_values(ascending=False).head(10)\n",
    "top_rev5 = top_rev.head(5)\n",
    "\n",
    "# Estatísticas gerais\n",
    "stats = {\n",
    "    'total_transactions': df['transaction_id'].nunique(),\n",
    "    'total_customers': df['customer_id'].nunique(),\n",
    "    'total_revenue': df['total'].sum(),\n",
    "    'avg_items_per_transaction': df.groupby('transaction_id')['product_id'].nunique().mean(),\n",
    "    'avg_transaction_value': df.groupby('transaction_id')['transaction_total'].first().mean()\n",
    "}\n",
    "print(stats)\n",
    "display(top_q5, top_rev5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaab086",
   "metadata": {},
   "source": [
    "### Visualização: Top 5 produtos mais vendidos (quantidade e receita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Top 5 quantidade and receita\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "top_q5.sort_values().plot.barh(ax=axes[0], title='Top 5 por Quantidade (unidades)')\n",
    "top_rev5.sort_values().plot.barh(ax=axes[1], title='Top 5 por Receita (R$)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605a8f7",
   "metadata": {},
   "source": [
    "## 4) Preparar dados para Apriori\n",
    "\n",
    "Criar o formato 'basket' (cada transação = conjunto de produtos) necessário para mineração de regras de associação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupar produtos por transação\n",
    "basket = df.groupby('transaction_id')['product_id'].apply(lambda x: list(set(x))).reset_index()\n",
    "basket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abdb85d",
   "metadata": {},
   "source": [
    "## 5) Mineração (Apriori)\n",
    "\n",
    "Implementamos uma versão simples do algoritmo Apriori para encontrar itemsets frequentes e gerar regras com suporte, confiança e lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def find_frequent_itemsets(transactions, min_support=0.01):\n",
    "    N = len(transactions)\n",
    "    item_counts = defaultdict(int)\n",
    "    for t in transactions:\n",
    "        for item in t:\n",
    "            item_counts[frozenset([item])] += 1\n",
    "    freq_itemsets = {}\n",
    "    L1 = {itemset: count/N for itemset, count in item_counts.items() if count/N >= min_support}\n",
    "    current_L = L1\n",
    "    k = 2\n",
    "    freq_itemsets.update(current_L)\n",
    "    while current_L:\n",
    "        candidates = set()\n",
    "        prev_itemsets = list(current_L.keys())\n",
    "        for a,b in combinations(prev_itemsets,2):\n",
    "            union = a.union(b)\n",
    "            if len(union) == k:\n",
    "                candidates.add(union)\n",
    "        candidate_counts = defaultdict(int)\n",
    "        for t in transactions:\n",
    "            tset = set(t)\n",
    "            for c in candidates:\n",
    "                if c.issubset(tset):\n",
    "                    candidate_counts[c] += 1\n",
    "        current_L = {c: count/N for c,count in candidate_counts.items() if count/N >= min_support}\n",
    "        freq_itemsets.update(current_L)\n",
    "        k += 1\n",
    "    return freq_itemsets\n",
    "\n",
    "def generate_rules(freq_itemsets, transactions, min_confidence=0.2):\n",
    "    supports = freq_itemsets\n",
    "    rules = []\n",
    "    for itemset in [iset for iset in supports.keys() if len(iset)>=2]:\n",
    "        for r in range(1, len(itemset)):\n",
    "            for antecedent in combinations(itemset, r):\n",
    "                antecedent = frozenset(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                if antecedent in supports and itemset in supports:\n",
    "                    conf = supports[itemset] / supports[antecedent]\n",
    "                    lift = supports[itemset] / (supports[antecedent]*supports[consequent]) if (supports.get(consequent,0)>0) else np.nan\n",
    "                    if conf >= min_confidence:\n",
    "                        rules.append({'antecedent': antecedent, 'consequent': consequent, 'support': supports[itemset], 'confidence': conf, 'lift': lift})\n",
    "    rules = sorted(rules, key=lambda x: x['lift'] if not np.isnan(x['lift']) else 0, reverse=True)\n",
    "    return rules\n",
    "\n",
    "transactions_list = basket['product_id'].tolist()\n",
    "freq_itemsets = find_frequent_itemsets(transactions_list, min_support=0.02)\n",
    "len(freq_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rules = generate_rules(freq_itemsets, transactions_list, min_confidence=0.25)\n",
    "# show top 10 rules\n",
    "rules[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2435e6c",
   "metadata": {},
   "source": [
    "### Regras de Associação mais fortes (exibir top por lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80be262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mostrar as principais regras em DataFrame\n",
    "rules_df = pd.DataFrame([{'antecedent': ','.join(sorted(list(r['antecedent']))),\n",
    "                          'consequent': ','.join(sorted(list(r['consequent']))),\n",
    "                          'support': r['support'],\n",
    "                          'confidence': r['confidence'],\n",
    "                          'lift': r['lift']} for r in rules])\n",
    "rules_df = rules_df.sort_values('lift', ascending=False).reset_index(drop=True)\n",
    "rules_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db59e7",
   "metadata": {},
   "source": [
    "## 6) Similaridade (Jaccard) entre clientes\n",
    "\n",
    "Construímos uma matriz binária cliente x produto e calculamos a similaridade Jaccard para identificar clientes com padrões semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar matriz cliente x produto (binary: 1 se cliente já comprou o produto)\n",
    "cust_prod = df.groupby(['customer_id','product_id']).size().unstack(fill_value=0)\n",
    "cust_prod = (cust_prod > 0).astype(int)\n",
    "\n",
    "# compute pairwise Jaccard similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "customers = cust_prod.index.tolist()\n",
    "X = cust_prod.values\n",
    "n = X.shape[0]\n",
    "jaccard_mat = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(i,n):\n",
    "        if i==j:\n",
    "            jaccard_mat[i,j] = 1.0\n",
    "        else:\n",
    "            score = jaccard_score(X[i], X[j])\n",
    "            jaccard_mat[i,j] = score\n",
    "            jaccard_mat[j,i] = score\n",
    "\n",
    "jaccard_df = pd.DataFrame(jaccard_mat, index=customers, columns=customers)\n",
    "jaccard_df.iloc[:6,:6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4ae55",
   "metadata": {},
   "source": [
    "### Visualização: Mapa de similaridade entre clientes\n",
    "\n",
    "Exibimos um heatmap reduzido e uma rede com as ligações de maior similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Heatmap (plot subset of customers to keep figure readable)\n",
    "subset = customers[:40]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(jaccard_df.loc[subset, subset].values, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(label='Jaccard similarity')\n",
    "plt.title('Heatmap de Similaridade Jaccard (subset 40 clientes)')\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Clientes')\n",
    "plt.xticks(ticks=np.arange(len(subset)), labels=[s.replace('Cliente_','') for s in subset], rotation=90, fontsize=6)\n",
    "plt.yticks(ticks=np.arange(len(subset)), labels=[s.replace('Cliente_','') for s in subset], fontsize=6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rede: conectar pares com Jaccard alto (>0.6) - somente top pares para visualização\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "threshold = 0.6\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        if jaccard_mat[i,j] >= threshold:\n",
    "            G.add_edge(customers[i], customers[j], weight=jaccard_mat[i,j])\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "if len(G.nodes)>0:\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=50)\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.6)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=6)\n",
    "    plt.title(f'Rede de clientes com Jaccard >= {threshold} (n_edges={len(G.edges)})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Nenhuma aresta com Jaccard >=', threshold, ' — experimente diminuir o threshold.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaeb27d",
   "metadata": {},
   "source": [
    "## 7) Resumo e próximos passos\n",
    "\n",
    "- Notebook inclui ETL, análise descritiva, Apriori e similaridade Jaccard.\n",
    "- Próximos passos sugeridos: ajustar thresholds de Apriori, incluir métricas temporais, integrar com dashboard interativo (Streamlit) e testes A/B para promoções.\n",
    "\n",
    "---\n",
    "\n",
    "Arquivo pronto para download abaixo."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
